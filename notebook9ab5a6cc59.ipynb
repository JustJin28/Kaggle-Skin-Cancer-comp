{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfba4928",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:02.884042Z",
     "iopub.status.busy": "2024-08-22T19:20:02.883703Z",
     "iopub.status.idle": "2024-08-22T19:20:16.916646Z",
     "shell.execute_reply": "2024-08-22T19:20:16.915679Z"
    },
    "papermill": {
     "duration": 14.041509,
     "end_time": "2024-08-22T19:20:16.919004",
     "exception": false,
     "start_time": "2024-08-22T19:20:02.877495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 19:20:05.427381: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-22 19:20:05.427487: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-22 19:20:05.560532: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, auc\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "import h5py\n",
    "import random\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5820aa7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:16.931923Z",
     "iopub.status.busy": "2024-08-22T19:20:16.930765Z",
     "iopub.status.idle": "2024-08-22T19:20:16.937041Z",
     "shell.execute_reply": "2024-08-22T19:20:16.935893Z"
    },
    "papermill": {
     "duration": 0.015581,
     "end_time": "2024-08-22T19:20:16.939538",
     "exception": false,
     "start_time": "2024-08-22T19:20:16.923957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88cac5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:16.954644Z",
     "iopub.status.busy": "2024-08-22T19:20:16.953965Z",
     "iopub.status.idle": "2024-08-22T19:20:16.959703Z",
     "shell.execute_reply": "2024-08-22T19:20:16.958635Z"
    },
    "papermill": {
     "duration": 0.015634,
     "end_time": "2024-08-22T19:20:16.961884",
     "exception": false,
     "start_time": "2024-08-22T19:20:16.946250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_metadata_path = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\n",
    "train_image_hdf5_path = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\n",
    "test_metadata_path = '/kaggle/input/isic-2024-challenge/test-metadata.csv'\n",
    "test_image_hdf5_path = '/kaggle/input/isic-2024-challenge/test-image.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "387de5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:16.973395Z",
     "iopub.status.busy": "2024-08-22T19:20:16.973059Z",
     "iopub.status.idle": "2024-08-22T19:20:16.981625Z",
     "shell.execute_reply": "2024-08-22T19:20:16.980679Z"
    },
    "papermill": {
     "duration": 0.017238,
     "end_time": "2024-08-22T19:20:16.984359",
     "exception": false,
     "start_time": "2024-08-22T19:20:16.967121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image_from_hdf5(hdf5_path, image_id):\n",
    "    with h5py.File(hdf5_path, 'r') as hdf:\n",
    "        # Load the raw data\n",
    "        image_data = hdf[image_id][()]\n",
    "        \n",
    "    # Convert the data to a numpy array\n",
    "    image_array = np.frombuffer(image_data, dtype=np.uint8)\n",
    "    \n",
    "    # Decode the image using OpenCV\n",
    "    image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # Convert BGR to RGB (OpenCV loads images in BGR format)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d05fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.000157Z",
     "iopub.status.busy": "2024-08-22T19:20:16.999798Z",
     "iopub.status.idle": "2024-08-22T19:20:17.005618Z",
     "shell.execute_reply": "2024-08-22T19:20:17.004956Z"
    },
    "papermill": {
     "duration": 0.015738,
     "end_time": "2024-08-22T19:20:17.007535",
     "exception": false,
     "start_time": "2024-08-22T19:20:16.991797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image, target_size=(224, 224)):\n",
    "    # Resize the image\n",
    "    image_resized = cv2.resize(image, target_size)\n",
    "    \n",
    "    # Normalize the image\n",
    "    image_normalized = image_resized.astype(np.float32) / 255.0\n",
    "    \n",
    "    return image_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6057537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.023760Z",
     "iopub.status.busy": "2024-08-22T19:20:17.022899Z",
     "iopub.status.idle": "2024-08-22T19:20:17.042968Z",
     "shell.execute_reply": "2024-08-22T19:20:17.042099Z"
    },
    "papermill": {
     "duration": 0.030424,
     "end_time": "2024-08-22T19:20:17.044895",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.014471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(metadata_path, hdf5_path, is_train=True, train_columns=None, train_encoders=None):\n",
    "    # Load metadata\n",
    "    data = pd.read_csv(metadata_path, low_memory=False)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['patient_id', 'copyright_license', 'attribution', 'image_type', \n",
    "                       'tbp_tile_type', 'lesion_id']\n",
    "    data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    # Handle missing values in numeric columns\n",
    "    numeric_columns = ['age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', \n",
    "                       'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', \n",
    "                       'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA', \n",
    "                       'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', \n",
    "                       'tbp_lv_minorAxisMM', 'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color', \n",
    "                       'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL', 'tbp_lv_stdLExt', \n",
    "                       'tbp_lv_symm_2axis', 'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z']\n",
    "    \n",
    "    if is_train:\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        data[numeric_columns] = imputer.fit_transform(data[numeric_columns])\n",
    "    else:\n",
    "        # Use the imputer fitted on training data\n",
    "        data[numeric_columns] = train_encoders['imputer'].transform(data[numeric_columns])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_columns = ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
    "    if is_train:\n",
    "        categorical_columns.extend(['iddx_full', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4', 'iddx_5'])\n",
    "        label_encoders = {}\n",
    "        for col in categorical_columns:\n",
    "            if col in data.columns:\n",
    "                le = LabelEncoder()\n",
    "                data[col] = data[col].fillna('Unknown')\n",
    "                data[col] = le.fit_transform(data[col].astype(str))\n",
    "                label_encoders[col] = le\n",
    "    else:\n",
    "        # Use the label encoders fitted on training data\n",
    "        for col in categorical_columns:\n",
    "            if col in data.columns:\n",
    "                data[col] = data[col].fillna('Unknown')\n",
    "                data[col] = train_encoders['label_encoders'][col].transform(data[col].astype(str))\n",
    "    \n",
    "    # One-hot encode relevant categorical variables\n",
    "    categorical_columns_to_onehot = ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
    "    if is_train:\n",
    "        data = pd.get_dummies(data, columns=categorical_columns_to_onehot)\n",
    "        train_columns = data.columns\n",
    "    else:\n",
    "        # For test data, add missing columns\n",
    "        for col in train_columns:\n",
    "            if col not in data.columns:\n",
    "                data[col] = 0\n",
    "        # Ensure test data has the same columns as train data\n",
    "        data = data[train_columns]\n",
    "    \n",
    "    # Scale numerical features\n",
    "    if is_train:\n",
    "        scaler = StandardScaler()\n",
    "        data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "    else:\n",
    "        # Use the scaler fitted on training data\n",
    "        data[numeric_columns] = train_encoders['scaler'].transform(data[numeric_columns])\n",
    "    \n",
    "    if is_train:\n",
    "        # Handle 'mel_mitotic_index' if present\n",
    "        if 'mel_mitotic_index' in data.columns:\n",
    "            mitotic_index_mapping = {\n",
    "                '<1/mm^2': 0, '0/mm^2': 0, '1/mm^2': 1, '2/mm^2': 2, \n",
    "                '3/mm^2': 3, '4/mm^2': 4, '>4/mm^2': 5\n",
    "            }\n",
    "            data['mel_mitotic_index'] = data['mel_mitotic_index'].map(mitotic_index_mapping).fillna(-1)\n",
    "        \n",
    "        # Handle 'mel_thick_mm' if present\n",
    "        if 'mel_thick_mm' in data.columns:\n",
    "            data['mel_thick_mm'] = pd.to_numeric(data['mel_thick_mm'], errors='coerce').fillna(-1)\n",
    "    \n",
    "    # Reset index\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # Print column names for debugging\n",
    "    print(f\"{'Train' if is_train else 'Test'} columns:\", data.columns)\n",
    "    \n",
    "    if is_train:\n",
    "        train_encoders = {\n",
    "            'imputer': imputer,\n",
    "            'label_encoders': label_encoders,\n",
    "            'scaler': scaler\n",
    "        }\n",
    "        return data, hdf5_path, train_columns, train_encoders\n",
    "    else:\n",
    "        return data, hdf5_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c66015d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.055978Z",
     "iopub.status.busy": "2024-08-22T19:20:17.055691Z",
     "iopub.status.idle": "2024-08-22T19:20:17.063995Z",
     "shell.execute_reply": "2024-08-22T19:20:17.063174Z"
    },
    "papermill": {
     "duration": 0.016136,
     "end_time": "2024-08-22T19:20:17.065870",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.049734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HDF5DataGenerator:\n",
    "    def __init__(self, data, hdf5_path, batch_size=32, dim=(224, 224), n_channels=3, shuffle=True, is_test=False):\n",
    "        self.data = data\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.is_test = is_test\n",
    "        self.feature_columns = [col for col in data.columns if col not in ['isic_id', 'target']]\n",
    "\n",
    "    def __call__(self):\n",
    "        indices = list(range(len(self.data)))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "    \n",
    "        for i in indices:\n",
    "            row = self.data.iloc[i]\n",
    "            img = load_image_from_hdf5(self.hdf5_path, row['isic_id'])\n",
    "            img_processed = preprocess_image(img, self.dim)\n",
    "        \n",
    "            tab_data = row[self.feature_columns].values\n",
    "        \n",
    "            if self.is_test:\n",
    "                yield img_processed, tab_data\n",
    "            else:\n",
    "                yield (img_processed, tab_data), row['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75b4ac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.077708Z",
     "iopub.status.busy": "2024-08-22T19:20:17.077002Z",
     "iopub.status.idle": "2024-08-22T19:20:17.084741Z",
     "shell.execute_reply": "2024-08-22T19:20:17.083884Z"
    },
    "papermill": {
     "duration": 0.015487,
     "end_time": "2024-08-22T19:20:17.086516",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.071029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(generator, data_size, batch_size, is_test=False):\n",
    "    feature_shape = (data_size.shape[1] - 2,) if 'target' in data_size.columns else (data_size.shape[1] - 1,)\n",
    "    \n",
    "    if is_test:\n",
    "        output_signature = (\n",
    "            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=feature_shape, dtype=tf.float32)\n",
    "        )\n",
    "    else:\n",
    "        output_signature = (\n",
    "            (tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n",
    "             tf.TensorSpec(shape=feature_shape, dtype=tf.float32)),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "        )\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=output_signature\n",
    "    )\n",
    "    \n",
    "    if not is_test:\n",
    "        dataset = dataset.shuffle(buffer_size=len(data_size)).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05145be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.097144Z",
     "iopub.status.busy": "2024-08-22T19:20:17.096878Z",
     "iopub.status.idle": "2024-08-22T19:20:17.102983Z",
     "shell.execute_reply": "2024-08-22T19:20:17.102145Z"
    },
    "papermill": {
     "duration": 0.013476,
     "end_time": "2024-08-22T19:20:17.104825",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.091349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Focal Loss implementation\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1 + K.epsilon())) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0 + K.epsilon()))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ccdbc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.115438Z",
     "iopub.status.busy": "2024-08-22T19:20:17.115183Z",
     "iopub.status.idle": "2024-08-22T19:20:17.120470Z",
     "shell.execute_reply": "2024-08-22T19:20:17.119712Z"
    },
    "papermill": {
     "duration": 0.012743,
     "end_time": "2024-08-22T19:20:17.122327",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.109584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to balance dataset\n",
    "def balance_dataset(data, undersample_ratio=0.5):\n",
    "    majority_class = data[data['target'] == 0]\n",
    "    minority_class = data[data['target'] == 1]\n",
    "    \n",
    "    # Undersample majority class\n",
    "    n_majority = int(len(minority_class) / (1 - undersample_ratio))\n",
    "    majority_undersampled = resample(majority_class, \n",
    "                                     n_samples=n_majority, \n",
    "                                     random_state=42)\n",
    "    \n",
    "    # Combine minority class with undersampled majority class\n",
    "    balanced_data = pd.concat([majority_undersampled, minority_class])\n",
    "    \n",
    "    return balanced_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61cabf0",
   "metadata": {
    "papermill": {
     "duration": 0.004754,
     "end_time": "2024-08-22T19:20:17.131977",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.127223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4227d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.142901Z",
     "iopub.status.busy": "2024-08-22T19:20:17.142595Z",
     "iopub.status.idle": "2024-08-22T19:20:17.152094Z",
     "shell.execute_reply": "2024-08-22T19:20:17.151214Z"
    },
    "papermill": {
     "duration": 0.01705,
     "end_time": "2024-08-22T19:20:17.153934",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.136884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(img_shape, tab_shape):\n",
    "    # Image input branch\n",
    "    img_input = Input(shape=img_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Tabular input branch\n",
    "    tab_input = Input(shape=(tab_shape,))\n",
    "    y = Dense(64, activation='relu')(tab_input)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dropout(0.3)(y)\n",
    "\n",
    "    # Combine branches\n",
    "    combined = Concatenate()([x, y])\n",
    "    z = Dense(32, activation='relu')(combined)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = Dropout(0.3)(z)\n",
    "    output = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "    model = Model(inputs=[img_input, tab_input], outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                  loss=focal_loss(alpha=.25, gamma=2),\n",
    "                  metrics=['accuracy', AUC(name='auc'), Precision(name='precision'), Recall(name='recall')])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9389b6ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.165380Z",
     "iopub.status.busy": "2024-08-22T19:20:17.165135Z",
     "iopub.status.idle": "2024-08-22T19:20:17.181413Z",
     "shell.execute_reply": "2024-08-22T19:20:17.180569Z"
    },
    "papermill": {
     "duration": 0.024488,
     "end_time": "2024-08-22T19:20:17.183396",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.158908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(train_data, train_hdf5_path, val_data=None, val_hdf5_path=None, n_splits=2, epochs=30, batch_size=32):\n",
    "    if val_data is None:\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        best_model = None\n",
    "        best_auc = 0\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(train_data, train_data['target'])):\n",
    "            print(f\"Training fold {fold + 1}\")\n",
    "            \n",
    "            train_data_fold = train_data.iloc[train_idx].reset_index(drop=True)\n",
    "            val_data_fold = train_data.iloc[val_idx].reset_index(drop=True)\n",
    "            \n",
    "            train_gen = HDF5DataGenerator(train_data_fold, train_hdf5_path, batch_size=batch_size)\n",
    "            val_gen = HDF5DataGenerator(val_data_fold, train_hdf5_path, batch_size=batch_size)\n",
    "            \n",
    "            train_dataset = create_dataset(train_gen, train_data_fold, batch_size)\n",
    "            val_dataset = create_dataset(val_gen, val_data_fold, batch_size)\n",
    "            \n",
    "            model = create_model((224, 224, 3), train_data.shape[1] - 2)\n",
    "            \n",
    "            # Define callbacks\n",
    "            model_checkpoint = ModelCheckpoint(\n",
    "                f'best_model_fold_{fold+1}.keras',\n",
    "                monitor='val_auc',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1\n",
    "            )\n",
    "            callbacks = [\n",
    "                EarlyStopping(patience=10, restore_best_weights=True),\n",
    "                ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6),\n",
    "                model_checkpoint\n",
    "            ]\n",
    "            \n",
    "            # Calculate steps per epoch\n",
    "            steps_per_epoch = math.ceil(len(train_data_fold) / batch_size)\n",
    "            validation_steps = math.ceil(len(val_data_fold) / batch_size)\n",
    "            \n",
    "            # Train model\n",
    "            history = model.fit(\n",
    "                train_dataset,\n",
    "                validation_data=val_dataset,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                validation_steps=validation_steps,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            \n",
    "            # Evaluate model\n",
    "            val_loss, val_accuracy, val_auc, val_precision, val_recall = model.evaluate(val_dataset, steps=validation_steps)\n",
    "            print(f\"Fold {fold + 1} - Validation Loss: {val_loss:.4f}, \"\n",
    "                  f\"Accuracy: {val_accuracy:.4f}, AUC: {val_auc:.4f}, \"\n",
    "                  f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\")\n",
    "            \n",
    "            # Calculate F1-score\n",
    "            f1_score = 2 * (val_precision * val_recall) / (val_precision + val_recall + K.epsilon())\n",
    "            print(f\"F1-score: {f1_score:.4f}\")\n",
    "            \n",
    "            # Keep track of the best model\n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_model = model\n",
    "    \n",
    "    else:\n",
    "        train_gen = HDF5DataGenerator(train_data, train_hdf5_path, batch_size=batch_size)\n",
    "        val_gen = HDF5DataGenerator(val_data, val_hdf5_path, batch_size=batch_size)\n",
    "        \n",
    "        train_dataset = create_dataset(train_gen, train_data, batch_size)\n",
    "        val_dataset = create_dataset(val_gen, val_data, batch_size)\n",
    "        \n",
    "        model = create_model((224, 224, 3), train_data.shape[1] - 2)\n",
    "        \n",
    "        # Define callbacks\n",
    "        model_checkpoint = ModelCheckpoint(\n",
    "            'best_model.keras',\n",
    "            monitor='val_auc',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        callbacks = [\n",
    "            EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6),\n",
    "            model_checkpoint\n",
    "        ]\n",
    "        \n",
    "        # Calculate steps per epoch\n",
    "        steps_per_epoch = math.ceil(len(train_data) / batch_size)\n",
    "        validation_steps = math.ceil(len(val_data) / batch_size)\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        best_model = model\n",
    "    \n",
    "    # Save the overall best model\n",
    "    best_model.save('best_model_overall.keras')\n",
    "    print(f\"Best model saved with validation AUC: {best_auc:.4f}\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3260567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.194564Z",
     "iopub.status.busy": "2024-08-22T19:20:17.194305Z",
     "iopub.status.idle": "2024-08-22T19:20:17.199763Z",
     "shell.execute_reply": "2024-08-22T19:20:17.198919Z"
    },
    "papermill": {
     "duration": 0.01319,
     "end_time": "2024-08-22T19:20:17.201595",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.188405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_class_distribution(data):\n",
    "    class_counts = data['target'].value_counts()\n",
    "    class_percentages = class_counts / len(data) * 100\n",
    "    \n",
    "    print(\"Class Distribution:\")\n",
    "    for class_label, count in class_counts.items():\n",
    "        percentage = class_percentages[class_label]\n",
    "        print(f\"Class {class_label}: {count} samples ({percentage:.2f}%)\")\n",
    "    \n",
    "    imbalance_ratio = class_counts.max() / class_counts.min()\n",
    "    print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be04a578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.213502Z",
     "iopub.status.busy": "2024-08-22T19:20:17.212855Z",
     "iopub.status.idle": "2024-08-22T19:20:17.221083Z",
     "shell.execute_reply": "2024-08-22T19:20:17.220206Z"
    },
    "papermill": {
     "duration": 0.01614,
     "end_time": "2024-08-22T19:20:17.222904",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.206764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, test_gen, test_metadata):\n",
    "    all_predictions = []\n",
    "    for i in range(len(test_gen)):\n",
    "        try:\n",
    "            batch = test_gen[i]\n",
    "            # Print batch information for debugging\n",
    "            print(f\"Batch {i} shapes - Image: {batch[0]['image_input'].shape}, Tabular: {batch[0]['tabular_input'].shape}\")\n",
    "            predictions = model.predict(batch[0], verbose=0)\n",
    "            all_predictions.append(predictions)\n",
    "            print(f\"Successfully predicted batch {i} with shape {predictions.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting batch {i}: {str(e)}\")\n",
    "            # Print more detailed error information\n",
    "            import traceback\n",
    "            print(traceback.format_exc())\n",
    "    \n",
    "    print(f\"Total batches processed: {len(test_gen)}\")\n",
    "    print(f\"Number of successful predictions: {len(all_predictions)}\")\n",
    "    \n",
    "    if not all_predictions:\n",
    "        raise ValueError(\"No predictions were made successfully. Check the error messages above for more details.\")\n",
    "    \n",
    "    predictions = np.concatenate(all_predictions).flatten()\n",
    "    \n",
    "    print(f\"Final predictions shape: {predictions.shape}\")\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission = pd.DataFrame({\n",
    "        'isic_id': test_metadata['isic_id'],\n",
    "        'target': predictions\n",
    "    })\n",
    "    \n",
    "    # Save submission file\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Predictions saved to 'submission.csv'\")\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f2243db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-22T19:20:17.234729Z",
     "iopub.status.busy": "2024-08-22T19:20:17.233967Z",
     "iopub.status.idle": "2024-08-22T19:53:01.034450Z",
     "shell.execute_reply": "2024-08-22T19:53:01.033451Z"
    },
    "papermill": {
     "duration": 1963.808724,
     "end_time": "2024-08-22T19:53:01.036727",
     "exception": false,
     "start_time": "2024-08-22T19:20:17.228003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: Index(['isic_id', 'target', 'age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A',\n",
      "       'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext',\n",
      "       'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2',\n",
      "       'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA',\n",
      "       'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n",
      "       'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM',\n",
      "       'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n",
      "       'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n",
      "       'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
      "       'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z', 'iddx_full', 'iddx_1', 'iddx_2',\n",
      "       'iddx_3', 'iddx_4', 'iddx_5', 'mel_mitotic_index', 'mel_thick_mm',\n",
      "       'tbp_lv_dnn_lesion_confidence', 'sex_0', 'sex_1', 'sex_2',\n",
      "       'anatom_site_general_0', 'anatom_site_general_1',\n",
      "       'anatom_site_general_2', 'anatom_site_general_3',\n",
      "       'anatom_site_general_4', 'anatom_site_general_5', 'tbp_lv_location_0',\n",
      "       'tbp_lv_location_1', 'tbp_lv_location_2', 'tbp_lv_location_3',\n",
      "       'tbp_lv_location_4', 'tbp_lv_location_5', 'tbp_lv_location_6',\n",
      "       'tbp_lv_location_7', 'tbp_lv_location_8', 'tbp_lv_location_9',\n",
      "       'tbp_lv_location_10', 'tbp_lv_location_11', 'tbp_lv_location_12',\n",
      "       'tbp_lv_location_13', 'tbp_lv_location_14', 'tbp_lv_location_15',\n",
      "       'tbp_lv_location_16', 'tbp_lv_location_17', 'tbp_lv_location_18',\n",
      "       'tbp_lv_location_19', 'tbp_lv_location_20', 'tbp_lv_location_simple_0',\n",
      "       'tbp_lv_location_simple_1', 'tbp_lv_location_simple_2',\n",
      "       'tbp_lv_location_simple_3', 'tbp_lv_location_simple_4',\n",
      "       'tbp_lv_location_simple_5', 'tbp_lv_location_simple_6',\n",
      "       'tbp_lv_location_simple_7'],\n",
      "      dtype='object')\n",
      "Original data distribution:\n",
      "Class Distribution:\n",
      "Class 0: 400666 samples (99.90%)\n",
      "Class 1: 393 samples (0.10%)\n",
      "\n",
      "Imbalance Ratio: 1019.51\n",
      "\n",
      "Balanced data distribution:\n",
      "Class Distribution:\n",
      "Class 0: 786 samples (66.67%)\n",
      "Class 1: 393 samples (33.33%)\n",
      "\n",
      "Imbalance Ratio: 2.00\n",
      "Training fold 1\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 19:21:21.812042: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49284: 7.84353, expected 6.92193\n",
      "2024-08-22 19:21:21.812101: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49286: 7.76792, expected 6.84632\n",
      "2024-08-22 19:21:21.812111: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49287: 6.15631, expected 5.23472\n",
      "2024-08-22 19:21:21.812119: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49288: 6.71859, expected 5.797\n",
      "2024-08-22 19:21:21.812127: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49289: 7.43913, expected 6.51753\n",
      "2024-08-22 19:21:21.812135: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49290: 7.1783, expected 6.25671\n",
      "2024-08-22 19:21:21.812143: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49291: 6.06838, expected 5.14679\n",
      "2024-08-22 19:21:21.812151: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49292: 6.24725, expected 5.32565\n",
      "2024-08-22 19:21:21.812159: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49293: 6.19403, expected 5.27243\n",
      "2024-08-22 19:21:21.812167: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49294: 7.10498, expected 6.18338\n",
      "2024-08-22 19:21:21.834411: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[32,32,222,222]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,224,224]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-08-22 19:21:21.834462: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-08-22 19:21:21.834476: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-08-22 19:21:21.834489: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n",
      "2024-08-22 19:21:21.834503: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-08-22 19:21:21.834525: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n",
      "2024-08-22 19:21:22.564923: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49284: 7.84353, expected 6.92193\n",
      "2024-08-22 19:21:22.564978: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49286: 7.76792, expected 6.84632\n",
      "2024-08-22 19:21:22.564988: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49287: 6.15631, expected 5.23472\n",
      "2024-08-22 19:21:22.564996: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49288: 6.71859, expected 5.797\n",
      "2024-08-22 19:21:22.565004: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49289: 7.43913, expected 6.51753\n",
      "2024-08-22 19:21:22.565012: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49290: 7.1783, expected 6.25671\n",
      "2024-08-22 19:21:22.565020: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49291: 6.06838, expected 5.14679\n",
      "2024-08-22 19:21:22.565028: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49292: 6.24725, expected 5.32565\n",
      "2024-08-22 19:21:22.565036: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49293: 6.19403, expected 5.27243\n",
      "2024-08-22 19:21:22.565044: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 49294: 7.10498, expected 6.18338\n",
      "2024-08-22 19:21:22.586940: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[32,32,222,222]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,224,224]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-08-22 19:21:22.586992: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-08-22 19:21:22.587001: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-08-22 19:21:22.587008: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n",
      "2024-08-22 19:21:22.587015: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-08-22 19:21:22.587050: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/19\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.5391 - auc: 0.4981 - loss: 0.3362 - precision: 0.3721 - recall: 0.5000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724354489.411591      71 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5598 - auc: 0.5573 - loss: 0.3019 - precision: 0.3969 - recall: 0.5332\n",
      "Epoch 1: val_auc improved from -inf to 0.61836, saving model to best_model_fold_1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 7s/step - accuracy: 0.5603 - auc: 0.5585 - loss: 0.3006 - precision: 0.3966 - recall: 0.5339 - val_accuracy: 0.7582 - val_auc: 0.6184 - val_loss: 0.0776 - val_precision: 0.9831 - val_recall: 0.2843 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5905 - auc: 0.5946 - loss: 0.3143 - precision: 0.4227 - recall: 0.5162\n",
      "Epoch 2: val_auc did not improve from 0.61836\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 5s/step - accuracy: 0.5905 - auc: 0.5958 - loss: 0.3118 - precision: 0.4224 - recall: 0.5169 - val_accuracy: 0.6678 - val_auc: 0.5803 - val_loss: 0.0636 - val_precision: 1.0000 - val_recall: 0.0049 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6571 - auc: 0.6959 - loss: 0.1766 - precision: 0.5015 - recall: 0.5774\n",
      "Epoch 3: val_auc did not improve from 0.61836\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.6572 - auc: 0.6960 - loss: 0.1769 - precision: 0.5009 - recall: 0.5776 - val_accuracy: 0.6678 - val_auc: 0.5137 - val_loss: 0.0674 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6375 - auc: 0.6759 - loss: 0.2250 - precision: 0.4604 - recall: 0.5790\n",
      "Epoch 4: val_auc did not improve from 0.61836\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4s/step - accuracy: 0.6372 - auc: 0.6747 - loss: 0.2251 - precision: 0.4596 - recall: 0.5787 - val_accuracy: 0.6711 - val_auc: 0.5139 - val_loss: 0.0688 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6497 - auc: 0.6700 - loss: 0.1953 - precision: 0.4698 - recall: 0.5730\n",
      "Epoch 5: val_auc did not improve from 0.61836\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 3s/step - accuracy: 0.6501 - auc: 0.6705 - loss: 0.1945 - precision: 0.4711 - recall: 0.5736 - val_accuracy: 0.6530 - val_auc: 0.5682 - val_loss: 0.0730 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6633 - auc: 0.7013 - loss: 0.1673 - precision: 0.4855 - recall: 0.6218\n",
      "Epoch 6: val_auc did not improve from 0.61836\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 0.6641 - auc: 0.7020 - loss: 0.1666 - precision: 0.4868 - recall: 0.6221 - val_accuracy: 0.6694 - val_auc: 0.6062 - val_loss: 0.0733 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6328 - auc: 0.6780 - loss: 0.1811 - precision: 0.4830 - recall: 0.5705\n",
      "Epoch 7: val_auc improved from 0.61836 to 0.70774, saving model to best_model_fold_1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 4s/step - accuracy: 0.6347 - auc: 0.6798 - loss: 0.1801 - precision: 0.4846 - recall: 0.5716 - val_accuracy: 0.6612 - val_auc: 0.7077 - val_loss: 0.0750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.6543 - auc: 0.7034 - loss: 0.1563 - precision: 0.4680 - recall: 0.5814\n",
      "Epoch 8: val_auc improved from 0.70774 to 0.77247, saving model to best_model_fold_1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 3s/step - accuracy: 0.6552 - auc: 0.7032 - loss: 0.1569 - precision: 0.4694 - recall: 0.5838 - val_accuracy: 0.6826 - val_auc: 0.7725 - val_loss: 0.0721 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.6957 - auc: 0.7422 - loss: 0.1660 - precision: 0.5373 - recall: 0.6500\n",
      "Epoch 9: val_auc did not improve from 0.77247\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.6954 - auc: 0.7407 - loss: 0.1664 - precision: 0.5371 - recall: 0.6483 - val_accuracy: 0.6562 - val_auc: 0.7661 - val_loss: 0.0767 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6974 - auc: 0.7313 - loss: 0.1262 - precision: 0.5260 - recall: 0.5541\n",
      "Epoch 10: val_auc improved from 0.77247 to 0.78580, saving model to best_model_fold_1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.6969 - auc: 0.7307 - loss: 0.1271 - precision: 0.5255 - recall: 0.5549 - val_accuracy: 0.6694 - val_auc: 0.7858 - val_loss: 0.0706 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - accuracy: 0.6896 - auc: 0.7199 - loss: 0.1808 - precision: 0.5274 - recall: 0.5982\n",
      "Epoch 11: val_auc did not improve from 0.78580\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.6909 - auc: 0.7213 - loss: 0.1796 - precision: 0.5304 - recall: 0.5997 - val_accuracy: 0.6562 - val_auc: 0.7538 - val_loss: 0.0739 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7420 - auc: 0.7887 - loss: 0.1207 - precision: 0.5890 - recall: 0.6811\n",
      "Epoch 12: val_auc improved from 0.78580 to 0.78809, saving model to best_model_fold_1.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5s/step - accuracy: 0.7423 - auc: 0.7883 - loss: 0.1208 - precision: 0.5900 - recall: 0.6801 - val_accuracy: 0.6711 - val_auc: 0.7881 - val_loss: 0.0657 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-05\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.6609 - auc: 0.5485 - loss: 0.0647 - precision: 0.2500 - recall: 0.0013\n",
      "Fold 1 - Validation Loss: 0.0640, Accuracy: 0.6628, AUC: 0.5716, Precision: 1.0000, Recall: 0.0049\n",
      "F1-score: 0.0097\n",
      "Training fold 2\n",
      "Epoch 1/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5509 - auc: 0.6283 - loss: 0.2617 - precision: 0.3981 - recall: 0.6704\n",
      "Epoch 1: val_auc improved from -inf to 0.39419, saving model to best_model_fold_2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 7s/step - accuracy: 0.5515 - auc: 0.6278 - loss: 0.2609 - precision: 0.3984 - recall: 0.6705 - val_accuracy: 0.4260 - val_auc: 0.3942 - val_loss: 0.1089 - val_precision: 0.2741 - val_recall: 0.4314 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5346 - auc: 0.6191 - loss: 0.2189 - precision: 0.3917 - recall: 0.6896\n",
      "Epoch 2: val_auc improved from 0.39419 to 0.47416, saving model to best_model_fold_2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 5s/step - accuracy: 0.5351 - auc: 0.6194 - loss: 0.2185 - precision: 0.3921 - recall: 0.6891 - val_accuracy: 0.3322 - val_auc: 0.4742 - val_loss: 0.1929 - val_precision: 0.3322 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5697 - auc: 0.6315 - loss: 0.1856 - precision: 0.4213 - recall: 0.6343\n",
      "Epoch 3: val_auc improved from 0.47416 to 0.51608, saving model to best_model_fold_2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 5s/step - accuracy: 0.5699 - auc: 0.6321 - loss: 0.1858 - precision: 0.4206 - recall: 0.6362 - val_accuracy: 0.3322 - val_auc: 0.5161 - val_loss: 0.1813 - val_precision: 0.3322 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6031 - auc: 0.6553 - loss: 0.1799 - precision: 0.4570 - recall: 0.7080\n",
      "Epoch 4: val_auc improved from 0.51608 to 0.54863, saving model to best_model_fold_2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - accuracy: 0.6040 - auc: 0.6564 - loss: 0.1797 - precision: 0.4576 - recall: 0.7079 - val_accuracy: 0.3372 - val_auc: 0.5486 - val_loss: 0.1991 - val_precision: 0.3372 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.6384 - auc: 0.7281 - loss: 0.1452 - precision: 0.4812 - recall: 0.7228\n",
      "Epoch 5: val_auc improved from 0.54863 to 0.59219, saving model to best_model_fold_2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3s/step - accuracy: 0.6372 - auc: 0.7269 - loss: 0.1456 - precision: 0.4798 - recall: 0.7213 - val_accuracy: 0.3322 - val_auc: 0.5922 - val_loss: 0.2183 - val_precision: 0.3322 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526ms/step - accuracy: 0.5883 - auc: 0.6639 - loss: 0.1678 - precision: 0.4024 - recall: 0.6404\n",
      "Epoch 6: val_auc improved from 0.59219 to 0.66669, saving model to best_model_fold_2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 3s/step - accuracy: 0.5880 - auc: 0.6641 - loss: 0.1681 - precision: 0.4033 - recall: 0.6418 - val_accuracy: 0.3306 - val_auc: 0.6667 - val_loss: 0.2202 - val_precision: 0.3306 - val_recall: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643ms/step - accuracy: 0.5984 - auc: 0.7264 - loss: 0.1488 - precision: 0.4053 - recall: 0.7372\n",
      "Epoch 7: val_auc did not improve from 0.66669\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 2s/step - accuracy: 0.5994 - auc: 0.7252 - loss: 0.1486 - precision: 0.4074 - recall: 0.7351 - val_accuracy: 0.3339 - val_auc: 0.6539 - val_loss: 0.2191 - val_precision: 0.3339 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6410 - auc: 0.7069 - loss: 0.1427 - precision: 0.4797 - recall: 0.6646\n",
      "Epoch 8: val_auc improved from 0.66669 to 0.70946, saving model to best_model_fold_2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5s/step - accuracy: 0.6405 - auc: 0.7070 - loss: 0.1430 - precision: 0.4785 - recall: 0.6647 - val_accuracy: 0.3306 - val_auc: 0.7095 - val_loss: 0.2247 - val_precision: 0.3306 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787ms/step - accuracy: 0.6836 - auc: 0.7305 - loss: 0.1355 - precision: 0.5191 - recall: 0.6877\n",
      "Epoch 9: val_auc did not improve from 0.70946\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.6836 - auc: 0.7304 - loss: 0.1357 - precision: 0.5186 - recall: 0.6879 - val_accuracy: 0.3240 - val_auc: 0.6593 - val_loss: 0.2348 - val_precision: 0.3240 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6270 - auc: 0.7277 - loss: 0.1553 - precision: 0.4932 - recall: 0.7215\n",
      "Epoch 10: val_auc improved from 0.70946 to 0.75879, saving model to best_model_fold_2.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 4s/step - accuracy: 0.6261 - auc: 0.7271 - loss: 0.1553 - precision: 0.4915 - recall: 0.7199 - val_accuracy: 0.3503 - val_auc: 0.7588 - val_loss: 0.2172 - val_precision: 0.3503 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708ms/step - accuracy: 0.6218 - auc: 0.6909 - loss: 0.1544 - precision: 0.4510 - recall: 0.6682\n",
      "Epoch 11: val_auc did not improve from 0.75879\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 0.6223 - auc: 0.6917 - loss: 0.1544 - precision: 0.4506 - recall: 0.6683 - val_accuracy: 0.3388 - val_auc: 0.7111 - val_loss: 0.2207 - val_precision: 0.3388 - val_recall: 1.0000 - learning_rate: 5.0000e-05\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.3997 - auc: 0.3604 - loss: 0.1097 - precision: 0.2568 - recall: 0.4030\n",
      "Fold 2 - Validation Loss: 0.1097, Accuracy: 0.4211, AUC: 0.3891, Precision: 0.2640, Recall: 0.4250\n",
      "F1-score: 0.3257\n",
      "Best model saved with validation AUC: 0.5716\n",
      "Test columns: Index(['isic_id', 'target', 'age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A',\n",
      "       'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext',\n",
      "       'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2',\n",
      "       'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA',\n",
      "       'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n",
      "       'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM',\n",
      "       'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n",
      "       'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n",
      "       'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
      "       'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z', 'iddx_full', 'iddx_1', 'iddx_2',\n",
      "       'iddx_3', 'iddx_4', 'iddx_5', 'mel_mitotic_index', 'mel_thick_mm',\n",
      "       'tbp_lv_dnn_lesion_confidence', 'sex_0', 'sex_1', 'sex_2',\n",
      "       'anatom_site_general_0', 'anatom_site_general_1',\n",
      "       'anatom_site_general_2', 'anatom_site_general_3',\n",
      "       'anatom_site_general_4', 'anatom_site_general_5', 'tbp_lv_location_0',\n",
      "       'tbp_lv_location_1', 'tbp_lv_location_2', 'tbp_lv_location_3',\n",
      "       'tbp_lv_location_4', 'tbp_lv_location_5', 'tbp_lv_location_6',\n",
      "       'tbp_lv_location_7', 'tbp_lv_location_8', 'tbp_lv_location_9',\n",
      "       'tbp_lv_location_10', 'tbp_lv_location_11', 'tbp_lv_location_12',\n",
      "       'tbp_lv_location_13', 'tbp_lv_location_14', 'tbp_lv_location_15',\n",
      "       'tbp_lv_location_16', 'tbp_lv_location_17', 'tbp_lv_location_18',\n",
      "       'tbp_lv_location_19', 'tbp_lv_location_20', 'tbp_lv_location_simple_0',\n",
      "       'tbp_lv_location_simple_1', 'tbp_lv_location_simple_2',\n",
      "       'tbp_lv_location_simple_3', 'tbp_lv_location_simple_4',\n",
      "       'tbp_lv_location_simple_5', 'tbp_lv_location_simple_6',\n",
      "       'tbp_lv_location_simple_7'],\n",
      "      dtype='object')\n",
      "\n",
      "Test data shape: (3, 83)\n",
      "Test data columns: Index(['isic_id', 'target', 'age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A',\n",
      "       'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', 'tbp_lv_C', 'tbp_lv_Cext',\n",
      "       'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', 'tbp_lv_Lext', 'tbp_lv_areaMM2',\n",
      "       'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', 'tbp_lv_deltaA',\n",
      "       'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n",
      "       'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM',\n",
      "       'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n",
      "       'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n",
      "       'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
      "       'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z', 'iddx_full', 'iddx_1', 'iddx_2',\n",
      "       'iddx_3', 'iddx_4', 'iddx_5', 'mel_mitotic_index', 'mel_thick_mm',\n",
      "       'tbp_lv_dnn_lesion_confidence', 'sex_0', 'sex_1', 'sex_2',\n",
      "       'anatom_site_general_0', 'anatom_site_general_1',\n",
      "       'anatom_site_general_2', 'anatom_site_general_3',\n",
      "       'anatom_site_general_4', 'anatom_site_general_5', 'tbp_lv_location_0',\n",
      "       'tbp_lv_location_1', 'tbp_lv_location_2', 'tbp_lv_location_3',\n",
      "       'tbp_lv_location_4', 'tbp_lv_location_5', 'tbp_lv_location_6',\n",
      "       'tbp_lv_location_7', 'tbp_lv_location_8', 'tbp_lv_location_9',\n",
      "       'tbp_lv_location_10', 'tbp_lv_location_11', 'tbp_lv_location_12',\n",
      "       'tbp_lv_location_13', 'tbp_lv_location_14', 'tbp_lv_location_15',\n",
      "       'tbp_lv_location_16', 'tbp_lv_location_17', 'tbp_lv_location_18',\n",
      "       'tbp_lv_location_19', 'tbp_lv_location_20', 'tbp_lv_location_simple_0',\n",
      "       'tbp_lv_location_simple_1', 'tbp_lv_location_simple_2',\n",
      "       'tbp_lv_location_simple_3', 'tbp_lv_location_simple_4',\n",
      "       'tbp_lv_location_simple_5', 'tbp_lv_location_simple_6',\n",
      "       'tbp_lv_location_simple_7'],\n",
      "      dtype='object')\n",
      "Test batch shape: (3, 224, 224, 3) (3, 81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 19:53:00.322232: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98570: 7.29926, expected 6.39021\n",
      "2024-08-22 19:53:00.322304: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98571: 6.54057, expected 5.63152\n",
      "2024-08-22 19:53:00.322325: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98572: 6.60398, expected 5.69494\n",
      "2024-08-22 19:53:00.322353: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98573: 6.72281, expected 5.81376\n",
      "2024-08-22 19:53:00.322368: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98574: 6.22525, expected 5.31621\n",
      "2024-08-22 19:53:00.322381: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98575: 5.68646, expected 4.77741\n",
      "2024-08-22 19:53:00.322394: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98576: 5.92668, expected 5.01763\n",
      "2024-08-22 19:53:00.322406: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98577: 6.31122, expected 5.40217\n",
      "2024-08-22 19:53:00.322418: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98578: 6.41406, expected 5.50501\n",
      "2024-08-22 19:53:00.322431: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98579: 3.92717, expected 3.01812\n",
      "2024-08-22 19:53:00.322459: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[3,32,222,222]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,3,224,224]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-08-22 19:53:00.322475: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-08-22 19:53:00.322487: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-08-22 19:53:00.322500: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n",
      "2024-08-22 19:53:00.322513: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-08-22 19:53:00.322533: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n",
      "2024-08-22 19:53:00.382058: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98570: 7.29926, expected 6.39021\n",
      "2024-08-22 19:53:00.382115: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98571: 6.54057, expected 5.63152\n",
      "2024-08-22 19:53:00.382134: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98572: 6.60398, expected 5.69494\n",
      "2024-08-22 19:53:00.382149: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98573: 6.72281, expected 5.81376\n",
      "2024-08-22 19:53:00.382162: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98574: 6.22525, expected 5.31621\n",
      "2024-08-22 19:53:00.382173: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98575: 5.68646, expected 4.77741\n",
      "2024-08-22 19:53:00.382186: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98576: 5.92668, expected 5.01763\n",
      "2024-08-22 19:53:00.382198: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98577: 6.31122, expected 5.40217\n",
      "2024-08-22 19:53:00.382212: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98578: 6.41406, expected 5.50501\n",
      "2024-08-22 19:53:00.382226: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 98579: 3.92717, expected 3.01812\n",
      "2024-08-22 19:53:00.382259: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n",
      "(f32[3,32,222,222]{3,2,1,0}, u8[0]{0}) custom-call(f32[3,3,224,224]{3,2,1,0}, f32[32,3,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=2,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n",
      "2024-08-22 19:53:00.382284: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n",
      "2024-08-22 19:53:00.382298: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n",
      "2024-08-22 19:53:00.382316: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12040 (550.90.7)\n",
      "2024-08-22 19:53:00.382331: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n",
      "2024-08-22 19:53:00.382350: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989ms/step\n",
      "Predictions saved to 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # When processing train data\n",
    "    train_data, train_hdf5_path, train_columns, train_encoders = load_and_preprocess_data(train_metadata_path, train_image_hdf5_path, is_train=True)\n",
    "\n",
    "    print(\"Original data distribution:\")\n",
    "    check_class_distribution(train_data)\n",
    "    \n",
    "    # Balance the dataset (if needed)\n",
    "    balanced_data = balance_dataset(train_data)\n",
    "    \n",
    "    print(\"\\nBalanced data distribution:\")\n",
    "    check_class_distribution(balanced_data)\n",
    "    \n",
    "    # Train model\n",
    "    best_model = train_model(balanced_data, train_hdf5_path)\n",
    "    \n",
    "    # When processing test data\n",
    "    test_data, test_hdf5_path = load_and_preprocess_data(test_metadata_path, test_image_hdf5_path, is_train=False, train_columns=train_columns, train_encoders=train_encoders)\n",
    "\n",
    "    print(\"\\nTest data shape:\", test_data.shape)\n",
    "    print(\"Test data columns:\", test_data.columns)\n",
    "    \n",
    "    # Create test generator and dataset\n",
    "    test_gen = HDF5DataGenerator(test_data, test_hdf5_path, is_test=True)\n",
    "    test_dataset = create_dataset(test_gen, test_data, batch_size=32, is_test=True)\n",
    "\n",
    "    # Print shapes before prediction\n",
    "    for batch in test_dataset.take(1):\n",
    "        print(\"Test batch shape:\", batch[0].shape, batch[1].shape)\n",
    "\n",
    "    # Make predictions on test set\n",
    "    predictions = []\n",
    "    for batch in test_dataset:\n",
    "        batch_predictions = best_model.predict(batch)\n",
    "        predictions.append(batch_predictions)\n",
    "\n",
    "    predictions = np.concatenate(predictions).flatten()\n",
    "\n",
    "    # Create submission DataFrame\n",
    "    submission = pd.DataFrame({\n",
    "        'isic_id': test_data['isic_id'],\n",
    "        'target': predictions\n",
    "    })\n",
    "\n",
    "    # Save submission file\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Predictions saved to 'submission.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1984.028067,
   "end_time": "2024-08-22T19:53:04.102616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-22T19:20:00.074549",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
